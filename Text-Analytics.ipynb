{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hDk9hDvOH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0e4b74-e918-4bf9-8856-4dcae72ce761"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_k0z66e38lG",
        "outputId": "e0b04631-fdfa-4269-8e83-7b362a796f25"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "#NLTK-------------------------------\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "# Import libraries for feature \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwGQK7KAd7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bd7e9a-a8c6-4485-a83f-2fd8bdd6bef1"
      },
      "source": [
        "#Read files\n",
        "textfile = r'/gdrive/My Drive/Comments.csv'\n",
        "textData = pd.read_csv(textfile) #creates a dataframe\n",
        "\n",
        "CustInfofile = r'/gdrive/My Drive/Customers.csv'\n",
        "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
        "\n",
        "print(textData.shape)\n",
        "print(CustInfoData.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 2)\n",
            "(2070, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOTk6C1Ao45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adfecf6-09d8-40ae-e33e-0578ed84c5e4"
      },
      "source": [
        "#Extract target column from Customer Info file\n",
        "y_train = CustInfoData[\"TARGET\"]\n",
        "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "                     \n",
        "\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuWYNz2Ep17l"
      },
      "source": [
        "#Tokenize - Split the sentences to lists of words\n",
        "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
        "\n",
        "export_csv = textData.to_csv(r'/gdrive/My Drive/TextDataTokenized1.csv')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use English stemmer.\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed2'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/newTextDataLS.csv')"
      ],
      "metadata": {
        "id": "zwityopp1P6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use English stemmer.\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed1'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/newTextDataPS.csv')"
      ],
      "metadata": {
        "id": "A10u1zX21R8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYXLU-u_v9R"
      },
      "source": [
        "# Use English stemmer.\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/newTextDataSS.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07E7VW7_y0d"
      },
      "source": [
        "\n",
        "#Join stemmed strings\n",
        "newTextData['CommentsTokenizedStemmed'] = newTextData['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/newTextData-Joined.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBguQloljam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510f1458-c1c1-4132-dbb3-2915ada43f70"
      },
      "source": [
        "#Do Bag-Of-Words model - Term - Document Matrix\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
        "TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmed)\n",
        "print(TD_counts.shape)\n",
        "print(TD_counts.dtype)\n",
        "print(count_vect.get_feature_names())\n",
        "#print(TD_counts)\n",
        "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
        "print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts.to_csv(r'/gdrive/My Drive/TD_counts-TokenizedStemmed.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 354)\n",
            "int64\n",
            "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n",
            "      0    1    2    3    4    5    6    7    8    9    ...  344  345  346  \\\n",
            "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "1       0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "2       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "2065    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2066    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2067    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2068    0    0    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "2069    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      347  348  349  350  351  352  353  \n",
            "0       1    0    0    0    0    0    0  \n",
            "1       0    0    0    0    0    0    0  \n",
            "2       0    0    0    0    0    0    0  \n",
            "3       0    0    0    0    0    0    0  \n",
            "4       0    0    0    0    0    0    0  \n",
            "...   ...  ...  ...  ...  ...  ...  ...  \n",
            "2065    0    0    0    0    0    0    0  \n",
            "2066    0    0    0    0    0    0    0  \n",
            "2067    0    0    0    0    0    0    0  \n",
            "2068    0    0    0    0    0    0    0  \n",
            "2069    0    0    0    0    0    0    0  \n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8TZYnAxQbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5c788-1f0a-428b-e2df-04011d7319b3"
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
        "print(X_train_tfidf.shape)\n",
        "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
        "print(DF_TF_IDF)\n",
        "export_csv= DF_TF_IDF.to_csv(r'/gdrive/My Drive/TFIDF_counts-TokenizedStemmed.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 354)\n",
            "      0    1    2    3        4    5    6    7    8         9    ...  344  \\\n",
            "0     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "1     0.0  0.0  0.0  0.0  0.27568  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "3     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "4     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "...   ...  ...  ...  ...      ...  ...  ...  ...  ...       ...  ...  ...   \n",
            "2065  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2066  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2067  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2068  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.772949  ...  0.0   \n",
            "2069  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "\n",
            "      345  346       347  348  349  350  351  352  353  \n",
            "0     0.0  0.0  0.209678  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "...   ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
            "2065  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2066  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2067  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2068  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2069  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[2070 rows x 354 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge files\n",
        "DF_TF_IDF['ID'] = textData['ID']\n",
        "combined = pd.merge(X_train, DF_TF_IDF, on ='ID')\n",
        "print(combined)\n",
        "\n",
        "\n",
        "export_csv= combined.to_csv(r'/gdrive/My Drive/Combined2-Cust+TFIDF+SelectedFeatures.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "airdjeZD96Jn",
        "outputId": "672fbf8e-4d3b-42b0-d5ea-3c4e69fc5f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID Sex Status  Children  Est_Income Car_Owner   Usage        Age  \\\n",
            "0        1   F      S         1    38000.00         N  229.64  24.393333   \n",
            "1        6   M      M         2    29616.00         N   75.29  49.426667   \n",
            "2        8   M      M         0    19732.80         N   47.25  50.673333   \n",
            "3       11   M      S         2       96.33         N   59.01  56.473333   \n",
            "4       14   F      M         2    52004.80         N   28.14  25.140000   \n",
            "...    ...  ..    ...       ...         ...       ...     ...        ...   \n",
            "2065  3821   F      S         0    78851.30         N   29.04  48.373333   \n",
            "2066  3822   F      S         1    17540.70         Y   36.20  62.786667   \n",
            "2067  3823   F      M         0    83891.90         Y   74.40  61.020000   \n",
            "2068  3824   F      M         2    28220.80         N   38.95  38.766667   \n",
            "2069  3825   F      S         0    28589.10         N  100.28  15.600000   \n",
            "\n",
            "      RatePlan  LongDistance  ...  344  345  346       347  348  349  350  \\\n",
            "0            3         23.56  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
            "1            2         29.78  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
            "2            3         24.81  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
            "3            1         26.13  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
            "4            1          5.03  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
            "...        ...           ...  ...  ...  ...  ...       ...  ...  ...  ...   \n",
            "2065         4          0.37  ...  0.0  0.0  0.0  0.356121  0.0  0.0  0.0   \n",
            "2066         1         22.17  ...  0.0  0.0  0.0  0.356121  0.0  0.0  0.0   \n",
            "2067         4         28.92  ...  0.0  0.0  0.0  0.356121  0.0  0.0  0.0   \n",
            "2068         4         26.49  ...  0.0  0.0  0.0  0.356121  0.0  0.0  0.0   \n",
            "2069         3         13.19  ...  0.0  0.0  0.0  0.356121  0.0  0.0  0.0   \n",
            "\n",
            "      351  352  353  \n",
            "0     0.0  0.0  0.0  \n",
            "1     0.0  0.0  0.0  \n",
            "2     0.0  0.0  0.0  \n",
            "3     0.0  0.0  0.0  \n",
            "4     0.0  0.0  0.0  \n",
            "...   ...  ...  ...  \n",
            "2065  0.0  0.0  0.0  \n",
            "2066  0.0  0.0  0.0  \n",
            "2067  0.0  0.0  0.0  \n",
            "2068  0.0  0.0  0.0  \n",
            "2069  0.0  0.0  0.0  \n",
            "\n",
            "[2070 rows x 370 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e0b990-0ca2-496c-ed18-ffee281af8cb",
        "id": "x3zZ1IalCYhF"
      },
      "source": [
        "#Do one Hot encoding for categorical features\n",
        "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
        "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
        "print(X_cat)\n",
        "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
        "print(combined_one_hot.shape)\n",
        "export_csv= combined_one_hot.to_csv(r'/gdrive/My Drive/combined_one_hot.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
            "(2070, 378)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2owIUD6_eYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5d6550-13d1-45aa-e025-4e3a7ea14f4b"
      },
      "source": [
        "#Feature selection\n",
        "#Suppose, we select 50 features with top 50 Fisher scores\n",
        "selector = SelectKBest(k=50)\n",
        "#selector = SelectKBest(score_func=chi2, k=25)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF_TF_IDF = selector.fit_transform(combined_one_hot,y_train)\n",
        "print(new_DF_TF_IDF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
        "print(DF_TF_IDF_SelectedFeatures)\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'/gdrive/My Drive/TFIDF_counts-Selected Features.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 50)\n",
            "[  1   2   3   6   7  14  17  32  37  38  40  49  50  84  97 107 123 128\n",
            " 129 135 151 164 174 178 184 193 208 209 230 234 244 255 266 277 292 298\n",
            " 300 304 306 307 320 325 338 345 357 364 365 367 368 371]\n",
            "       0         1       2      3     4    5    6         7         8    9   \\\n",
            "0     1.0  38000.00  229.64  23.56  0.00  0.0  0.0  0.000000  0.000000  0.0   \n",
            "1     2.0  29616.00   75.29  29.78  0.00  0.0  0.0  0.000000  0.000000  0.0   \n",
            "2     0.0  19732.80   47.25  24.81  0.00  0.0  0.0  0.000000  0.000000  0.0   \n",
            "3     2.0     96.33   59.01  26.13  0.00  0.0  0.0  0.000000  0.000000  0.0   \n",
            "4     2.0  52004.80   28.14   5.03  0.00  0.0  0.0  0.000000  0.000000  0.0   \n",
            "...   ...       ...     ...    ...   ...  ...  ...       ...       ...  ...   \n",
            "2065  0.0  78851.30   29.04   0.37  0.00  0.0  0.0  0.466708  0.443664  0.0   \n",
            "2066  1.0  17540.70   36.20  22.17  0.57  0.0  0.0  0.466708  0.443664  0.0   \n",
            "2067  0.0  83891.90   74.40  28.92  0.00  0.0  0.0  0.466708  0.443664  0.0   \n",
            "2068  2.0  28220.80   38.95  26.49  0.00  0.0  0.0  0.466708  0.443664  0.0   \n",
            "2069  0.0  28589.10  100.28  13.19  0.00  0.0  0.0  0.466708  0.443664  0.0   \n",
            "\n",
            "      ...   40   41        42        43        44   45   46   47   48   49  \n",
            "0     ...  0.0  0.0  0.000000  0.000000  0.000000  1.0  0.0  0.0  1.0  0.0  \n",
            "1     ...  0.0  0.0  0.348322  0.000000  0.000000  0.0  1.0  1.0  0.0  0.0  \n",
            "2     ...  0.0  0.0  0.348322  0.000000  0.000000  0.0  1.0  1.0  0.0  0.0  \n",
            "3     ...  0.0  0.0  0.348322  0.000000  0.000000  0.0  1.0  0.0  1.0  0.0  \n",
            "4     ...  0.0  0.0  0.348322  0.000000  0.000000  1.0  0.0  1.0  0.0  0.0  \n",
            "...   ...  ...  ...       ...       ...       ...  ...  ...  ...  ...  ...  \n",
            "2065  ...  0.0  0.0  0.000000  0.214868  0.356121  1.0  0.0  0.0  1.0  0.0  \n",
            "2066  ...  0.0  0.0  0.000000  0.214868  0.356121  1.0  0.0  0.0  1.0  1.0  \n",
            "2067  ...  0.0  0.0  0.000000  0.214868  0.356121  1.0  0.0  1.0  0.0  0.0  \n",
            "2068  ...  0.0  0.0  0.000000  0.214868  0.356121  1.0  0.0  1.0  0.0  0.0  \n",
            "2069  ...  0.0  0.0  0.000000  0.214868  0.356121  1.0  0.0  0.0  1.0  0.0  \n",
            "\n",
            "[2070 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "clf=RandomForestClassifier()\n",
        "DF_TF_IDF_SelectedFeatures, X_test, y_train, y_test = train_test_split(DF_TF_IDF_SelectedFeatures, y_train, test_size=0.2, random_state=1)\n",
        "RF_Comb = clf.fit(DF_TF_IDF_SelectedFeatures,y_train)\n",
        "print(\"Training Accuracy score (training): {0:.6f}\".format(clf.score(DF_TF_IDF_SelectedFeatures, y_train)))\n",
        "rf_predictions = clf.predict(X_test)\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test,rf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf0X-ChbESwO",
        "outputId": "b00e8718-d1f7-4843-8182-c6ec4c08e8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy score (training): 0.930556\n",
            "Test Accuracy: 0.8743961352657005\n",
            "Confusion Matrix:\n",
            "[[130  20]\n",
            " [ 32 232]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.80      0.87      0.83       150\n",
            "     Current       0.92      0.88      0.90       264\n",
            "\n",
            "    accuracy                           0.87       414\n",
            "   macro avg       0.86      0.87      0.87       414\n",
            "weighted avg       0.88      0.87      0.88       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RDRxnDRkcxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc4e682-5ffa-4989-a789-fff7442dc97e"
      },
      "source": [
        "#run cross-validation - COMBINED Data\n",
        "rf_Comb_cv_score = cross_val_score(RF_Comb, DF_TF_IDF_SelectedFeatures, y_train, cv=20, scoring=\"balanced_accuracy\")\n",
        "print(\"=== All Accuracy Scores ===\")\n",
        "print(rf_Comb_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean Accuracy Score ===\")\n",
        "print(\"Mean Accuracy Score - ON Text: \",rf_Comb_cv_score.mean())\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== All Accuracy Scores ===\n",
            "[0.88939394 0.80378788 0.77348485 0.90550595 0.73958333 0.8422619\n",
            " 0.79613095 0.79613095 0.74032738 0.90550595 0.7485119  0.70833333\n",
            " 0.82738095 0.69196429 0.8735119  0.78794643 0.8578869  0.75669643\n",
            " 0.82738095 0.8       ]\n",
            "\n",
            "\n",
            "=== Mean Accuracy Score ===\n",
            "Mean Accuracy Score - ON Text:  0.8035863095238096\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf1MEHy8I1f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0579eecf-eeba-4efb-aefd-b257dd3729cb"
      },
      "source": [
        "#Construct a Random Forest Classifier WITHOUT text data\n",
        "print(CustInfoData.shape)\n",
        "X_train1=combined_one_hot.iloc[:,1:10]\n",
        "#X_train2=combined_one_hot.iloc[:,60:]\n",
        "X_train2=combined_one_hot.iloc[:,35:]\n",
        "print(X_train1.shape)\n",
        "print(X_train1.head())\n",
        "print(X_train2.shape)\n",
        "print(X_train2.head())\n",
        "combined1=pd.concat([X_train1, X_train2], axis=1)\n",
        "print(combined1.shape)\n",
        "print(combined1.head())\n",
        "export_csv= combined1.to_csv(r'/gdrive/My Drive/combined1.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 17)\n",
            "(2070, 9)\n",
            "   Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
            "0         1    38000.00  229.64  24.393333         3         23.56   \n",
            "1         2    29616.00   75.29  49.426667         2         29.78   \n",
            "2         0    19732.80   47.25  50.673333         3         24.81   \n",
            "3         2       96.33   59.01  56.473333         1         26.13   \n",
            "4         2    52004.80   28.14  25.140000         1          5.03   \n",
            "\n",
            "   International   Local  Dropped  \n",
            "0            0.0  206.08        0  \n",
            "1            0.0   45.50        0  \n",
            "2            0.0   22.44        0  \n",
            "3            0.0   32.88        1  \n",
            "4            0.0   23.11        0  \n",
            "(2070, 343)\n",
            "    25   26   27   28   29   30   31   32   33   34  ...  Status_S  \\\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         1   \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         1   \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...         0   \n",
            "\n",
            "   Car_Owner_N  Car_Owner_Y  Paymethod_Auto  Paymethod_CC  Paymethod_CH  \\\n",
            "0            1            0               0             1             0   \n",
            "1            1            0               0             0             1   \n",
            "2            1            0               0             1             0   \n",
            "3            1            0               0             1             0   \n",
            "4            1            0               0             0             1   \n",
            "\n",
            "   LocalBilltype_Budget  LocalBilltype_FreeLocal  \\\n",
            "0                     1                        0   \n",
            "1                     0                        1   \n",
            "2                     0                        1   \n",
            "3                     1                        0   \n",
            "4                     1                        0   \n",
            "\n",
            "   LongDistanceBilltype_Intnl_discount  LongDistanceBilltype_Standard  \n",
            "0                                    1                              0  \n",
            "1                                    0                              1  \n",
            "2                                    0                              1  \n",
            "3                                    0                              1  \n",
            "4                                    1                              0  \n",
            "\n",
            "[5 rows x 343 columns]\n",
            "(2070, 352)\n",
            "   Children  Est_Income   Usage        Age  RatePlan  LongDistance  \\\n",
            "0         1    38000.00  229.64  24.393333         3         23.56   \n",
            "1         2    29616.00   75.29  49.426667         2         29.78   \n",
            "2         0    19732.80   47.25  50.673333         3         24.81   \n",
            "3         2       96.33   59.01  56.473333         1         26.13   \n",
            "4         2    52004.80   28.14  25.140000         1          5.03   \n",
            "\n",
            "   International   Local  Dropped   25  ...  Status_S  Car_Owner_N  \\\n",
            "0            0.0  206.08        0  0.0  ...         1            1   \n",
            "1            0.0   45.50        0  0.0  ...         0            1   \n",
            "2            0.0   22.44        0  0.0  ...         0            1   \n",
            "3            0.0   32.88        1  0.0  ...         1            1   \n",
            "4            0.0   23.11        0  0.0  ...         0            1   \n",
            "\n",
            "   Car_Owner_Y  Paymethod_Auto  Paymethod_CC  Paymethod_CH  \\\n",
            "0            0               0             1             0   \n",
            "1            0               0             0             1   \n",
            "2            0               0             1             0   \n",
            "3            0               0             1             0   \n",
            "4            0               0             0             1   \n",
            "\n",
            "   LocalBilltype_Budget  LocalBilltype_FreeLocal  \\\n",
            "0                     1                        0   \n",
            "1                     0                        1   \n",
            "2                     0                        1   \n",
            "3                     1                        0   \n",
            "4                     1                        0   \n",
            "\n",
            "   LongDistanceBilltype_Intnl_discount  LongDistanceBilltype_Standard  \n",
            "0                                    1                              0  \n",
            "1                                    0                              1  \n",
            "2                                    0                              1  \n",
            "3                                    0                              1  \n",
            "4                                    1                              0  \n",
            "\n",
            "[5 rows x 352 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry-uqdi6DZZm"
      },
      "source": [
        "#Customer Info One-Hot Encoded\n",
        "DF_Combined1= pd.DataFrame(combined1)\n",
        "export_csv= DF_Combined1.to_csv(r'/gdrive/My Drive/CustInfo_Onehot_encoded.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7xNgybX8Khh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eff011d-4347-40e7-80ed-fb2407086704"
      },
      "source": [
        "#Do feature selection using a classification model\n",
        "#clf = ExtraTreesClassifier(n_estimators=50)\n",
        "#clf = GradientBoostingClassifier(n_estimators=50)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(combined_one_hot,y_train)\n",
        "print(clf.feature_importances_)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "model = SelectFromModel(clf, prefit=True, max_features=7, threshold=-np.inf)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "X_new= model.transform(combined_one_hot)\n",
        "X_new_SelectedFeatures= pd.DataFrame(X_new)\n",
        "export_csv= X_new_SelectedFeatures.to_csv(r'/gdrive/My Drive/X_new_SelectedFeatures.csv')\n",
        "\n",
        "#print(model.get_support())\n",
        "print(X_new_SelectedFeatures)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15644251 0.11368969 0.06562802 0.01254953 0.0603501  0.05578326\n",
            " 0.11246673 0.00221866 0.00547783 0.00747667 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00187125 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00241532 0.         0.         0.         0.\n",
            " 0.         0.         0.00070396 0.         0.         0.00187474\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00135578 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00077156\n",
            " 0.         0.00135578 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00669183\n",
            " 0.         0.         0.         0.         0.         0.00019772\n",
            " 0.         0.0049951  0.00044598 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.00064929 0.         0.\n",
            " 0.         0.         0.         0.00135578 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00015714 0.         0.         0.00045362\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.00463077\n",
            " 0.         0.03319884 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.00087499 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01424352 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.00067789 0.\n",
            " 0.00033141 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.00109787 0.\n",
            " 0.         0.         0.00018228 0.         0.13325763 0.\n",
            " 0.         0.         0.         0.00227657 0.00313766 0.\n",
            " 0.         0.         0.         0.         0.         0.00135578\n",
            " 0.         0.03859114 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.00077866 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.00162694 0.         0.         0.\n",
            " 0.         0.00051203 0.         0.         0.         0.00039241\n",
            " 0.         0.         0.         0.01476748 0.         0.\n",
            " 0.         0.         0.         0.00059508 0.         0.00174315\n",
            " 0.00233453 0.00162694 0.05008485 0.         0.00218774 0.05206222\n",
            " 0.00577417 0.         0.00760352 0.         0.00396455 0.00271156]\n",
            "           0    1         2          3    4      5         6\n",
            "0        1.0  1.0  38000.00  24.393333  3.0  23.56  0.000000\n",
            "1        6.0  2.0  29616.00  49.426667  2.0  29.78  0.271105\n",
            "2        8.0  0.0  19732.80  50.673333  3.0  24.81  0.271105\n",
            "3       11.0  2.0     96.33  56.473333  1.0  26.13  0.271105\n",
            "4       14.0  2.0  52004.80  25.140000  1.0   5.03  0.271105\n",
            "...      ...  ...       ...        ...  ...    ...       ...\n",
            "2065  3821.0  0.0  78851.30  48.373333  4.0   0.37  0.000000\n",
            "2066  3822.0  1.0  17540.70  62.786667  1.0  22.17  0.000000\n",
            "2067  3823.0  0.0  83891.90  61.020000  4.0  28.92  0.000000\n",
            "2068  3824.0  2.0  28220.80  38.766667  4.0  26.49  0.000000\n",
            "2069  3825.0  0.0  28589.10  15.600000  3.0  13.19  0.000000\n",
            "\n",
            "[2070 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf=RandomForestClassifier()\n",
        "X_new_SelectedFeatures, X_test, y_train, y_test = train_test_split(X_new_SelectedFeatures, y_train, test_size=0.2, random_state=1)\n",
        "RF_Comb = clf.fit(X_new_SelectedFeatures,y_train)\n",
        "print(\" Training Accuracy score (training): {0:.6f}\".format(clf.score(X_new_SelectedFeatures, y_train)))\n",
        "rf_predictions = clf.predict(X_test)\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test,rf_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiMEPMqRK955",
        "outputId": "7093e81d-acff-4684-d5c0-34e9ce52787c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training Accuracy score (training): 1.000000\n",
            "Test Accuracy: 0.8840579710144928\n",
            "Confusion Matrix:\n",
            "[[130  20]\n",
            " [ 28 236]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.82      0.87      0.84       150\n",
            "     Current       0.92      0.89      0.91       264\n",
            "\n",
            "    accuracy                           0.88       414\n",
            "   macro avg       0.87      0.88      0.88       414\n",
            "weighted avg       0.89      0.88      0.88       414\n",
            "\n"
          ]
        }
      ]
    }
  ]
}